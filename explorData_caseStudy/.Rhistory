str(bb2)
bb2=sqldf("select AGEP where unique from acs")
url="http://biostat.jhsph.edu/~jleek/contact.html "
library(httr)
html=GET(url)
content1=content(html,as="text")
str(content1)
parsedhtml=htmlParse(content1,asText=T)
library(XML)
parsedhtml=htmlParse(content1,asText=T)
str(parsedhtml)
head(parsedhtml)
htmlcode=readLines(url)
close(url)
nchar(htmlcode[10])
nchar(c(htmlcode[10],htmlcode[20]))
nchar(c(htmlcode[10],htmlcode[20],htmlcode[30]))
nchar(c(htmlcode[10],htmlcode[20],htmlcode[30],htmlcode[40]))
nchar(c(htmlcode[10],htmlcode[20],htmlcode[30],htmlcode[100]))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",dest="1.for",method="curl")
doc=read.table("1.for")
doc=read.table("1.for",header=T)
doc=read.table("1.for",skip=2, header=T)
doc=read.table("1.for",skip=3, header=T)
doc=read.table("1.for",skip=4, header=T)
x <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(x)
?read.fwf
sum(x[,4])
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
x=read.fwf("getdata-data-ss06pid.csv",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
sum(x[,4])
head(x)
w=c(1,9,4,9,4,9,4,9,4,9)
x=read.fwf("getdata-data-ss06pid.csv",skip=4,widths=w)
head(x)
w=c(11,4,9,4,9,4,9,4,9)
x=read.fwf("getdata-data-ss06pid.csv",skip=4,widths=w)
head(x)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
x=read.fwf("getdata-data-ss06pid.csv",skip=4,widths=w)
head(x)
w=c(11,4,9,4,9,4,9,4,9)
x=read.fwf("getdata-data-ss06pid.csv",skip=4,widths=w)
x=read.fwf("getdata-wksst8110.for",skip=4,widths=w)
head(x)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
x=read.fwf("getdata-wksst8110.for",skip=4,widths=w)
head(x)
w <- c(1, 9, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5)
x=read.fwf("getdata-wksst8110.for",skip=4,widths=w)
head(x)
sum(x[,7])
library(ggplot2)
install.packages("ggplot2")
demos(ggplot2)
?ggplot2
?transform
library(ggplot2)
str(mpg)
qplot(displ,hwy,data=mpg)
qplot(displ,hwy,data=mpg,color=drv)
qplot(displ,hwy,data=mpg,color=drv,geom=c("point","smooth"))
qplot(hwy,data=mpg,fill=drv)
qplot(displ,hwy,data=mpg,facets=.~drv)
qplot(displ,hwy,data=mpg,facets=drv.~)
qplot(displ,hwy,data=mpg,facets=drv~.)
str(maacs)
require(datasets)
str(maacs)
maacs=readRDS("maacs_env.rds")
str(maacs)
qplot(pm25,no2,data=maacs)
g=ggplot(maacs,aes(pm25,no2))
g+geom_point()
g+geom_point()+geom_smooth(method=“lm")
g+geom_point()+geom_smooth(method="lm")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
str(factor(Month))
str(factor(airquality$Month))
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
plot(p)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(votes, rating, data = movies) + stats_smooth("loess")
m=matrix(data=cbind(rnorm(30,0),rnorm(30,2),rnorm(30,5)),nrow=30,ncol=3)
head(m)
str(m)
type(m)
mode(m)
typeof(m)
summary(m)
library(ggplot2)
qplot(V1,V2,data=m)
qplot(V1,V2,data=as.dataframe(m))
?apply
apply(m,1,mean)
apply(m,2,mean)
apply(m,2,function(x) length(x[x<0]))
apply(m,2,function(x) x[x<0])
apply(m,2,function(x) x<0)
apply(m,2,function(x) x[x<0])
apply(m,2,function(x) length(x[x<0])
)
apply(m,2,is.vector)
apply(m,1,is.vector)
sample(1:5)
?rbind
fileUrl="￼"
fileUrl="https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD￼￼￼"
download.file(fileUrl,destfile="restaurants.csv",method="curl")
restData=read.csv("restaurants.csv")
head(restData)
restData=read.csv("restaurants.csv")
head(restData)
tail(restData,n=3)
names(restData)
str(restData)
typeof(restData)
quantile(restData$councilDistrict)
quantile(restData$councilDistrict,na.rm = T)
table(restData$zipCode,useNA = "ifany")
?table
apply(restData,2,function(x) sum(is.na(x)))
names(restData)
apply(restData,1,function(x) sum(is.na(x)))
any(is.na(restData$councilDistrict>0))
any(is.na(restData$councilDistrict0))
colSums(is.na(restData))
all(colSums(is.na(restData))==0)
table(restData$zipCode %in% c("21232","21212"))
table(restData$zipCode in c("21232","21212"))
restData[restData$zipCode %in% c("21212")]
restData[restData$zipCode %in% c("21212"),]
head(warbreaks)
library(datasets)
head(warbreaks)
head(warpbreaks)
warpbreaks$replicate=rep(1:9,len=54)
str(warpbreaks)
xt=xtabs(breaks~.,data=warpbreaks)
xt
apply(warpbreaks,1,mean)
head(warpbreaks)
apply(warpbreaks,2,mean)
str(warpbreaks)
mean(warpbreaks$breaks)
head(restData)
restData$nearMe=restData$neighborhood %in% c(""Roland Park)
restData$nearMe=restData$neighborhood %in% c(""Roland Park"")
restData$nearMe=restData$neighborhood %in% c("Roland Park")
table(restData$nearMe)
str(restData)
restData$ZipWrong=ifelse(restData$zipCode<0,T,F)
restData#zipGroup=cut(resD)
restData#zipGroup=cut(restData$zipCode,breaks=quantile(restData$zipCode))
？relevel
?relevel
yesno=sample(c("yes","no"),size=10,replace=T)
yesno
yesnofac=factor(yesno,levels=c("yes","no"))
yesnofac
relevel(yesnofac,ref="yes")
relevel(yesnofac,ref="no")
as.numeric(yesnofac)
head(restData$zipCode)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
?cut2
library(plyr)
?mutate
library(reshape2)
head(mtcars)
str(mtcars)
names(mtcars)
rwonames(mtcars)
rownames(mtcars)
?dcast
?tapply
?ddply
?ave
spraySums=ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum))
spraySums
ddply(InsectSprays,.(spray),summarize, sum=sum(count))
?ddply
?merge
authors <- data.frame(
surname = I(c("Tukey", "Venables", "Tierney", "Ripley", "McNeil")),
nationality = c("US", "Australia", "US", "UK", "Australia"),
deceased = c("yes", rep("no", 4)))
books <- data.frame(
name = I(c("Tukey", "Venables", "Tierney",
"Ripley", "Ripley", "McNeil", "R Core")),
title = c("Exploratory Data Analysis",
"Modern Applied Statistics ...",
"LISP-STAT",
"Spatial Statistics", "Stochastic Simulation",
"Interactive Data Analysis",
"An Introduction to R"),
other.author = c(NA, "Ripley", NA, NA, NA, NA,
"Venables & Smith"))
authors
books
intersect(authors,books)
m1=merge(authors,books)
m1
m1[m1$"surname"=="Tukey",]
m1=merge(authors,books,by.x="surname",by.y="name")
m1
books
authors
unique(authors#authors)
$authors)
unique(authors$surname)
names(books)
names(authors)
authors
books
rm(list=ls())
fileurl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileurl,dest="data.csv",method="curl")
data=read.csv("data.csv")
str(data)
table(data$ACR)
table(data$AGS)
aa=(data$ACR==3 & data$AGS==6)
str(aa)
sum(aa)
sum(data$ACR)
which(aa)
library(jpeg)
install.packages("jpeg")
require(jpeg)
?readJPEG
fileurl="https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileurl,dest="1.jpg",method="curl")
pic=readJPEG("1.jpg",native = T)
str(pic)
typeof(pic)
class(pic)
quantile(pic,c(0.3,0.8))
?intersect
fileurl1="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
fileurl2="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileurl1,"dest=gdp.csv",method="curl")
download.file(fileurl2,"edu.csv",method="auto")
download.file(fileurl2,"edu.csv",method="curl")
gdpdf=read.csv("dest=gdp.csv")
str(gdpdf)
names(gdpdf)
gdpdf=read.csv("GDP.csv")
str(gdpdf)
gdpdf=read.csv("dest=gdp.csv",skip=3)
str(gdpdf)
gdpdf=read.csv("dest=gdp.csv",skip=5)
str(gdpdf)
gdpdf=read.csv("dest=gdp.csv",skip=5,header = F)
str(gdpdf)
fileurl1
fileurl2
download.file(fileurl1,"gdp.csv")
download.file(fileurl1,"gdp.csv",method="curl")
download.file(fileurl2,"edu.csv",method="curl")
gdp=read.csv("gdp.csv")
str(gdp)
head(gdp)
gdp=read.csv("gdp.csv",skip=3)
head(gdp)
rownames(gdp)
colnames(gdp)
edu=read.csv("edu.csv")
head(edu)
str(edu)
length(intersect(gdp$X,edu$CountryCode))
head(gdp)
unique(gdp$X)
m1=merge(gdp,edu,by.x=X,by.y=CountryCode)
colnames(gdp)[1]
colnames(gdp)[1]="code"
m1=merge(gdp,edu,by.x=code,by.y=CountryCode)
head(gdp)
m1=merge(gdp,edu,by.x="code",by.y="CountryCode")
nrow(m1)
ncol(m1)
arrange(gdp,desc(US.dolloars))
arrange(gdp,desc(US.dollors))
arrange(gdp,desc(US.dollors.))
arrange(gdp,desc(US.dollars.))
data_ranked=arrange(gdp,desc(US.dollors))
data_ranked=arrange(gdp,desc(US.dollars))
data_ranked=arrange(gdp,desc(US.dollars.))
head(data_ranked)
m1$"High income:OECD"
names(m1)
names(edu)
rm(list=ls())
dtGDP=data.table(read.csv("gdp.csv",skip=4,nrows=215))
library(data.table)
dtGDP=data.table(read.csv("gdp.csv",skip=4,nrows=215))
head(dtGDP)
dtGDP=dtGDP[X!=""]
head(dtGDP)
dtGDP
dtGDP=data.table(read.csv("gdp.csv",skip=3,nrows=215))
dtGDP
dtGDP=dtGDP[X!=""]
dtGDP
dtGDP=dtGDP[,list(X,Ranking,Economy,US.dollars.)]
setnames(dtGDP,c("X","Ranking","Economy","US.dollars"),c("CountryCode","rankingGDP","Long.Name","gdp"))
names(dtGDP)
setnames(dtGDP,c("X","Ranking","Economy","US.dollars."),c("CountryCode","rankingGDP","Long.Name","gdp"))
dtEd=datatable(read.csv("edu.csv"))
dtEd=data.table(read.csv("edu.csv"))
dt=merge(dtGDP,dtEd,all=T,by=c("countryCode"))
dt=merge(dtGDP,dtEd,all=T,by=c("CountryCode"))
length(intersect(dtGDP$CountryCode, dtEd$CountryCode))
sum(!is.na(unique(dt$rankingGDP)))
names(dt)
colnames(dt)
dt$Income.Group
dt[order(rankingGDP,decreasing=T),list(CountryCode,Long.Name.x,long.Name.y,rankingGDP,gdp)][13]
dt[order(rankingGDP,decreasing=T),list(CountryCode,Long.Name.x,Long.Name.y,rankingGDP,gdp)][13]
dt[,mean(rankingGDP,na.rm=T),by=Income.Group]
breaks=quantile(dt$rankingGDP, probs=seq(0,1,length=5),na.rm=T)
breaks
dt$quantileGDP=cut(dt$rankingGDP,breaks=breaks)
dt[Income.Group=="Lower middle income",.N,by=c("Income.Group","quantileGDP")]
(0,1,length=5)
seq(0,1,length=5)
seq(0,1,length=4)
seq(0,1,length=6)
breaks=quantile(dt$rankingGDP, probs=seq(0,1,length=6),na.rm=T)
dt$quantileGDP=cut(dt$rankingGDP,breaks=breaks)
dt[Income.Group=="Lower middle income",.N,by=c("Income.Group","quantileGDP")]
sum(!is.na(unique(dt$rankingGDP)))
sum(!is.na(unique(dt$CountryCode)))
load(datasets)
load(dataset)
head(iris)
str(iris)
load(dplyer)
load(dplyr)
load(ddply)
?ddply
load(plry)
load(plyr)
load(ddply)
library(ddply)
library(plyr)
head(InsectSprays)
str(iris)
unique(iris$Petal.Width)
iris$Petal.Width = as.factor(iris$Petal.Width)
?ddply
ddply(iris,.(Species), summarise, mean=mean(Petal.Length))
ddply(iris,.(Species, Petal.Width), summarise, mean=mean(Petal.Length))
ddply(iris,.(Species, Petal.Width), summarise, numcolwise(mean))
ddply(iris,.(Species), summarise, numcolwise(mean))
d2=Sys.date()
d2=sys.date()
library(sys)
library(Sys)
install.packages("Sys")
install.packages("sys")
library(Lubridate)
install.packages("Lubridate")
install.packages("lubridate")
Sys.time()
Sys.Time()
Sys.time()
fileurl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileurl, dest="1.csv", method="curl")
aa=load("1.csv")
aa=read.csv("1.csv")
str(aa)
summary(aa)
colnames(aa)
?strsplit
bb=strsplit(colnames(aa),"wgtp")
bb[123]
fileurl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileurl, dest="2.csv",method="curl")
rm(list=ls())
aa=read.csv("2.csv")
str(aa)
View(aa)
aa=read.csv("2.csv",skip=5)
View(aa)
str(aa)
aa=read.csv("2.csv",skip=5,header=F)
str(aa)
View(aa)
aa$V5 = gsub(",","",aa$V5)
summary(aa$V5)
aa$V5 = as.numeric(aa$V5)
mean(aa$V5, na.rm = F)
mean(aa$V5, na.rm = T)
View(aa)
aa$V5[is.na(aa$V5)]=0
mean(aa$V5, na.rm = F)
View(aa)
rm(aa)
aa=read.csv("2.csv", skip=5, header = F, stringsAsFactor=F)
View(aa)
bb=as.numeric(aa$V5)
sum(is.na(bb))
nrow(bb)
ncol(bb)
summary(bb)
mean(bb,na.rm=T)
aa$V5=gsub(",","", aa$V5)
View(aa)
bb=as.numeric(aa$V5)
summary(bb)
mean(bb, na.rm=T)
mean(bb, na.rm=F)
cc=bb[1:231]
mean(cc)
mean(cc,na.rm=T)
str(aa)
grep("^United", aa$V4)
cc=bb[1:190]
mean(cc,na.rm = T)
fileurl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileurl, dest="gdp.csv",method="curl")
gdp=read.csv("gdp.csv", skip=5, stringsAsFactor=F)
fileurl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileurl,dest="edu.csv",method="curl")
edu=read.csv("edu.csv")
View(gdp)
gdp=read.csv("gdp.csv", skip=4, stringsAsFactor=F)
View(gdp)
View(edu)
mthstr="Fiscal year end: June"
grep(mthstr, edu$Special.Notes)
sum(grepl(mthstr,edu$Special.Notes))
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn=getSymbols("AMZN",auto.assign=F)
?getSymbol
?getSymbols
sampleTimes=index(amzn)
View(amzn)
colnames(amzn)
amzn[,1]
str(amzn)
sampleTimes=index(amzn)
?index
str(sampleTimes)
dates=as.date(sampleTimes)
dates=as.Date(sampleTimes)
dates
sum(grepl("2012", dates))
pm0 <- read.table("pm25_data/RD_501_88101_1999-0.txt", comment.char = "#", header = FALSE, sep = "|", na.strings = "")
setwd("~/code/rLearning/playground/explorData_caseStudy")
pm0 <- read.table("pm25_data/RD_501_88101_1999-0.txt", comment.char = "#", header = FALSE, sep = "|", na.strings = "")
head(pm0)
cnames <- readLines("pm25_data/RD_501_88101_1999-0.txt", 1)
print(cnames)
make.names(cnames[[1]])
cnames <- strsplit(cnames, "|", fixed = TRUE)
print(cnames)
cnames[[1]]
class(cnames)
str(cnames)
cnames[[1]]
cnames[[2]]
unlist(cnames)
make.names(cnames[[1]])
?make.names
names(pm0) <- make.names(cnames[[1]])
head(pm0)
pm1 <- read.table("pm25_data/RD_501_88101_2012-0.txt", comment.char = "#", header = FALSE, sep = "|", na.strings = "", nrow = 1304290)
1304287*28*8/1024/1024
names(pm1) <- make.names(cnames[[1]])
head(pm1)
dim(pm1)
x1 <- pm1$Sample.Value
class(x1)
x0 <- pm0$Sample.Value
class(x0)
str(x0)
summary(x1)
summary(x0)
is.na(x1)
boxplot(x0,x1)
Sys.Date()
a=["1","2"]
a=c("1","2")
b=c("1")
b %in % a
b %in% a
b=c("1","d")
b %in% a
